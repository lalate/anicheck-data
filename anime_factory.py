import json
import os
import re

# --- è¨­å®š: å·¥å ´ã®ãƒ©ã‚¤ãƒ³æ§‹æˆ ---
INPUT_FILE = 'raw_grok_output.txt'
OUTPUT_FILES = {
    'master': 'master.json',
    'episode': 'episode.json',
    'broadcast': 'broadcast.json'
}

def clean_text(text):
    """
    Grok/LLMç‰¹æœ‰ã®ãƒã‚¤ã‚ºã‚’é™¤å»ã—ã€æ¨™æº–çš„ãªJSONå½¢å¼ã«è¿‘ã¥ã‘ã‚‹å‰å‡¦ç†ã€‚
    """
    # ã‚¹ãƒãƒ¼ãƒˆã‚¯ã‚©ãƒ¼ãƒˆï¼ˆå…¨è§’ï¼‰ã‚’åŠè§’ã«ç½®æ›
    text = text.replace('â€œ', '"').replace('â€', '"')
    # Markdownã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯è¨˜å·ã‚’é™¤å»
    text = re.sub(r'^```\w*\n|```$', '', text.strip(), flags=re.MULTILINE)
    return text.strip()

def parse_json_stream(text):
    """
    Grokã®ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆã«åŸ‹ã‚‚ã‚ŒãŸJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚„ãƒªã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ã€‚
    """
    decoder = json.JSONDecoder()
    pos = 0
    items = []
    
    while pos < len(text):
        # æ¬¡ã®JSONé–‹å§‹è¨˜å·ï¼ˆ{ ã¾ãŸã¯ [ï¼‰ã‚’æ¢ã™
        match = re.search(r'[\[\{]', text[pos:])
        if not match:
            break
        
        start_index = pos + match.start()
        
        try:
            # è¦‹ã¤ã‘ãŸä½ç½®ã‹ã‚‰ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
            obj, index = decoder.raw_decode(text[start_index:])
            
            # ãƒªã‚¹ãƒˆãªã‚‰å±•é–‹ã€è¾æ›¸ãªã‚‰è¿½åŠ 
            if isinstance(obj, list):
                items.extend(obj)
            elif isinstance(obj, dict):
                items.append(obj)
            
            # èª­ã¿çµ‚ã‚ã£ãŸä½ç½®ã¾ã§ãƒã‚¤ãƒ³ã‚¿ã‚’é€²ã‚ã‚‹
            pos = start_index + index
        except json.JSONDecodeError:
            # ãƒ‘ãƒ¼ã‚¹å¤±æ•—ï¼ˆãŸã ã®æ‹¬å¼§ã ã£ãŸå ´åˆãªã©ï¼‰ã¯1æ–‡å­—é€²ã‚ã¦å†è©¦è¡Œ
            pos = start_index + 1
            
    return items

def classify_data(items):
    """
    ã‚¢ã‚¤ãƒ†ãƒ ã®ç‰¹å¾´ã«åŸºã¥ã„ã¦3ã¤ã®ã‚«ãƒ†ã‚´ãƒªã«è‡ªå‹•ä»•åˆ†ã‘ã™ã‚‹ã€‚
    """
    classified = {'master': [], 'episode': [], 'broadcast': []}

    for item in items:
        keys = item.keys()
        
        # Broadcast: æ”¾é€å±€IDã¨é–‹å§‹æ™‚é–“ãŒã‚ã‚‹
        if 'station_id' in keys and 'start_time' in keys:
            classified['broadcast'].append(item)
        # Episode: è©±æ•°ãŒã‚ã‚Šã€ã‹ã¤æ”¾é€æ ãƒ‡ãƒ¼ã‚¿ã§ã¯ãªã„ï¼ˆã‚ã‚‰ã™ã˜ç­‰ãŒã‚ã‚‹ï¼‰
        elif 'ep_num' in keys:
            classified['episode'].append(item)
        # Master: ã‚­ãƒ£ã‚¹ãƒˆã€ã‚¹ã‚¿ãƒƒãƒ•ã€å…¬å¼ã‚µã‚¤ãƒˆãªã©ã®åŸºæœ¬æƒ…å ±ãŒã‚ã‚‹
        elif 'cast' in keys or 'staff' in keys or 'official_url' in keys:
            classified['master'].append(item)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: IDã¨ã‚¿ã‚¤ãƒˆãƒ«ã ã‘ãªã‚‰Masteræ‰±ã„ã¨ã™ã‚‹
            if 'anime_id' in keys and 'title' in keys:
                classified['master'].append(item)
            else:
                print(f"âš ï¸ Warning: åˆ†é¡ä¸èƒ½ãªãƒ‡ãƒ¼ã‚¿ -> {item}")

    return classified

def main():
    print(f"ğŸ­ Anime Data Factory ç¨¼åƒé–‹å§‹...")
    
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ Error: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« '{INPUT_FILE}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        raw_content = f.read()

    cleaned_content = clean_text(raw_content)
    items = parse_json_stream(cleaned_content)
    
    classified = classify_data(items)

    for category, data in classified.items():
        filename = OUTPUT_FILES[category]
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        print(f"âœ… {category.upper().ljust(9)} : {len(data)} ä»¶ã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()